---
phase: 21-chat-interface
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/functions/openrouter-coach-chat/index.ts
autonomous: true
user_setup:
  - service: supabase
    why: "Edge Function deployment"
    env_vars: []
    dashboard_config: []

must_haves:
  truths:
    - "Edge Function accepts POST requests with message and patterns_data"
    - "JWT authentication validates user tokens (401 on invalid)"
    - "Chat responses stream via SSE using Deno ReadableStream"
    - "Message history (last 20) and patterns are included in LLM context"
    - "SSE headers include text/event-stream, no-cache, keep-alive"
  artifacts:
    - path: "supabase/functions/openrouter-coach-chat/index.ts"
      provides: "SSE streaming chat endpoint"
      min_lines: 150
      contains: "ReadableStream", "stream: true", "coach_messages"
  key_links:
    - from: "supabase/functions/openrouter-coach-chat/index.ts"
      to: "coach_messages table"
      via: "Supabase query for message history"
      pattern: "supabase.from\\('coach_messages'\\)"
    - from: "supabase/functions/openrouter-coach-chat/index.ts"
      to: "OpenRouter API"
      via: "OpenAI SDK with streaming"
      pattern: "openai.chat.completions.create.*stream: true"
---

<objective>
Create Supabase Edge Function for streaming chat responses with SSE, JWT authentication, and context-aware prompts

Purpose: Build the backend foundation for free-form chat that streams AI responses in real-time while including message history and climbing patterns as context
Output: Edge Function at supabase/functions/openrouter-coach-chat/index.ts with SSE streaming
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/21-chat-interface/21-RESEARCH.md

@supabase/functions/openrouter-coach/index.ts
@src/types/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Edge Function handler with JWT auth and CORS</name>
  <files>supabase/functions/openrouter-coach-chat/index.ts</files>
  <action>
Create Edge Function following the openrouter-coach pattern:

1. Create file supabase/functions/openrouter-coach-chat/index.ts
2. Import dependencies: createClient, OpenAI, corsHeaders from _shared/cors.ts
3. Validate required environment variables (OPENROUTER_API_KEY, SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)
4. Initialize Supabase client (service role) and OpenAI client with OpenRouter baseURL
5. Implement Deno.serve handler with:
   - CORS preflight (OPTIONS method, return 204 with corsHeaders)
   - Method validation (only POST allowed, 405 otherwise)
   - JWT token extraction from Authorization header
   - Token validation using supabase.auth.getUser() (return 401 on invalid)

6. Define TypeScript interfaces matching coach_messages table and request body:
   - RequestBody: { user_id, message, patterns_data }
   - PatternAnalysis: matches existing patterns service types
   - CoachMessage: role, content, created_at

Do NOT include streaming logic in this task - just the handler skeleton and auth.
</action>
  <verify>cat supabase/functions/openrouter-coach-chat/index.ts | grep -E "(Deno.serve|corsHeaders|auth.getUser)"</verify>
  <done>Edge Function file exists with Deno.serve handler, CORS support, and JWT token extraction/validation</done>
</task>

<task type="auto">
  <name>Task 2: Message history fetching and context prompt building</name>
  <files>supabase/functions/openrouter-coach-chat/index.ts</files>
  <action>
Add message history fetching and prompt construction:

1. After JWT auth and request body parsing (user_id, message, patterns_data):
   - Fetch last 20 messages from coach_messages table for the user
   - Order by created_at ascending to maintain conversation flow
   - Filter to only include role and content fields

2. Define chatSystemPrompt constant:
   - Role: "You are an expert climbing coach specializing in bouldering and sport climbing"
   - Instructions: Reference user's patterns when relevant, use climbing terminology (beta, send, project, crimp, sloper, hangboard, campus board), be concise and actionable, ask clarifying questions if needed
   - Context injection: Include patterns_data in system prompt (failure reasons, style weaknesses, climbing frequency, recent successes)

3. Build messages array combining:
   - System prompt with injected patterns
   - Message history (map to { role, content } format)
   - Current user message (role: 'user', content: body.message)

4. Add user_id validation: Ensure request body user_id matches authenticated user (403 on mismatch)

Reference: supabase/functions/openrouter-coach/index.ts for buildUserPrompt pattern
</action>
  <verify>cat supabase/functions/openrouter-coach-chat/index.ts | grep -E "(coach_messages|chatSystemPrompt|messages.*role)"</verify>
  <done>Message history fetched (last 20), system prompt with patterns defined, messages array built with context</done>
</task>

<task type="auto">
  <name>Task 3: SSE streaming response with OpenRouter</name>
  <files>supabase/functions/openrouter-coach-chat/index.ts</files>
  <action>
Implement streaming chat response with SSE:

1. Create ReadableStream with start(controller) and cancel() methods:
   - Use for-await loop over openai.chat.completions.create() response
   - Model: 'google/gemini-2.5-pro' (same as openrouter-coach)
   - Stream: true
   - Temperature: 0.7 (slightly higher for conversational chat)
   - Pass messages array from Task 2

2. Inside streaming loop:
   - Extract content from chunk.choices[0]?.delta?.content
   - If content exists, enqueue SSE event: controller.enqueue(\`data: \${JSON.stringify({ content })}\\n\\n\`)
   - Handle errors in stream (log and call controller.error())

3. After stream completes, close controller and save assistant message to coach_messages:
   - Accumulate full response content
   - Insert into coach_messages: { role: 'assistant', content: accumulatedResponse, context: { patterns_data } }
   - Track API usage in coach_api_usage table (same as openrouter-coach)

4. Return Response with stream and SSE headers:
   - Content-Type: text/event-stream
   - Cache-Control: no-cache
   - Connection: keep-alive
   - corsHeaders

Reference: supabase/functions/openrouter-coach/index.ts for API usage tracking pattern
</action>
  <verify>cat supabase/functions/openrouter-coach-chat/index.ts | grep -E "(ReadableStream|controller.enqueue|text/event-stream|stream: true)"</verify>
  <done>SSE streaming implemented with ReadableStream, OpenRouter streaming, and message persistence</done>
</task>

</tasks>

<verification>
1. Edge Function file exists at supabase/functions/openrouter-coach-chat/index.ts (min 150 lines)
2. JWT authentication validates tokens and returns 401 on invalid auth
3. Message history fetches last 20 messages from coach_messages table
4. System prompt includes climbing patterns context (failures, styles, frequency)
5. SSE streaming uses ReadableStream with text/event-stream headers
6. OpenRouter API call uses stream: true with google/gemini-2.5-pro model
7. Assistant messages are saved to coach_messages after streaming completes
8. CORS headers are properly configured for cross-origin requests
</verification>

<success_criteria>
1. POST to Edge Function with valid JWT returns SSE stream
2. Invalid JWT returns 401 error
3. Streaming responses include real-time text chunks in SSE format
4. Message history is included in LLM context for conversation continuity
5. Pattern analysis data is injected into system prompt for climbing-specific responses
6. Assistant messages are persisted to database for future context
</success_criteria>

<output>
After completion, create `.planning/phases/21-chat-interface/21-01-SUMMARY.md`
</output>
